{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crf测试pku中文语料第2版\n",
    "\n",
    "改进： 测试集从7/3划分改成从训练集中随机抽取一句带地名/人名的话。\n",
    "\n",
    "结果： 预测的label与真实label仍一摸一样，即precision/recall仍全是1。\n",
    "\n",
    "bug:  在做特征提取时，将label作为一个特征来训练了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    train_sents = []\n",
    "    f = open('./train_utf16.ner', 'r', encoding='utf_16_le')\n",
    "    pairList = []\n",
    "    for line in f:\n",
    "        line = line.encode('utf-8').decode('utf-8-sig').strip()  # 去掉首字前的\\ufeff\n",
    "        if line:\n",
    "            l = line.split(' ')\n",
    "            pairList.append([l[0], l[1]])\n",
    "        else:\n",
    "            train_sents.append(pairList)\n",
    "            pairList = []\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23182\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['这', 'N'], ['里', 'N'], ['刊', 'N'], ['登', 'N'], ['湖', 'B-LOC'], ['南', 'I-LOC'], ['读', 'N'], ['者', 'N'], ['周', 'B-PER'], ['云', 'I-PER'], ['武', 'I-PER'], ['的', 'N'], ['来', 'N'], ['稿', 'N'], ['—', 'N'], ['—', 'N'], ['—', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[888])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['一', 'N'], ['周', 'N'], ['来', 'N'], ['，', 'N'], ['河', 'B-LOC'], ['南', 'I-LOC'], ['西', 'B-LOC'], ['峡', 'I-LOC'], ['符', 'B-PER'], ['祖', 'I-PER'], ['国', 'I-PER'], ['、', 'N'], ['江', 'B-LOC'], ['西', 'I-LOC'], ['广', 'B-LOC'], ['昌', 'I-LOC'], ['吴', 'B-PER'], ['小', 'I-PER'], ['毛', 'I-PER'], ['、', 'N'], ['河', 'B-LOC'], ['北', 'I-LOC'], ['石', 'B-LOC'], ['家', 'I-LOC'], ['庄', 'I-LOC'], ['马', 'B-PER'], ['强', 'I-PER'], ['等', 'N'], ['百', 'N'], ['余', 'N'], ['位', 'N'], ['朋', 'N'], ['友', 'N'], ['给', 'N'], ['本', 'N'], ['刊', 'N'], ['来', 'N'], ['信', 'N'], ['来', 'N'], ['稿', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[889])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = train_sents[888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['这', 'N'], ['里', 'N'], ['刊', 'N'], ['登', 'N'], ['湖', 'B-LOC'], ['南', 'I-LOC'], ['读', 'N'], ['者', 'N'], ['周', 'B-PER'], ['云', 'I-PER'], ['武', 'I-PER'], ['的', 'N'], ['来', 'N'], ['稿', 'N'], ['—', 'N'], ['—', 'N'], ['—', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):  # for i in range(len(sent))\n",
    "    word = sent[i][0]\n",
    "    label = sent[i][1]\n",
    "    features = [  # 每个当前字的features\n",
    "        'bias',\n",
    "        'word=' + word,\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'label=' + label,\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        label1 = sent[i - 1][1]\n",
    "        features.extend([  # 前一个单词的features\n",
    "            '-1:word=' + word1,\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:postag=' + label1,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i + 1][0]\n",
    "        label1 = sent[i + 1][1]\n",
    "        features.extend([  # 后一个单词的features\n",
    "            '+1:word=' + word1,\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:label=' + label1,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bias', 'word=藏', 'word.istitle=False', 'word.isdigit=False', 'label=N', 'BOS', '+1:word=书', '+1:word.istitle=False', '+1:label=N']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(train_sents[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "print(sent2labels(train_sents[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]  # 不加[]是generator类型，不会输出。加了[]，可直接输出加了[]之后的结果。\n",
    "y_train = [sent2labels(s) for s in train_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [sent2features(test_sents)]  # 格式 [[[每个word的特征],[每个word的特征]],（到此处是一个s）,[(每个word的特征)],...]，\n",
    "y_test = [sent2labels(test_sents)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose=False，是否在训练时输出debug信息\n",
    "trainer = pycrfsuite.Trainer(verbose=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer中的数据\n",
    "for xseq, yseq in zip(X_train, y_train): \n",
    "    trainer.append(xseq, yseq)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer的设置参数\n",
    "trainer.set_params({\n",
    "    'c1':1.0,\n",
    "    'c2':1e-3,\n",
    "    'max_iterations':50,\n",
    "    'feature.possible_transitions':True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer.params(): ['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']\n"
     ]
    }
   ],
   "source": [
    "print('trainer.params():', trainer.params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer得出的模型\n",
    "trainer.train('conll2002_2.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f4e3bde0b38>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002_2.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sents: [['这', 'N'], ['里', 'N'], ['刊', 'N'], ['登', 'N'], ['湖', 'B-LOC'], ['南', 'I-LOC'], ['读', 'N'], ['者', 'N'], ['周', 'B-PER'], ['云', 'I-PER'], ['武', 'I-PER'], ['的', 'N'], ['来', 'N'], ['稿', 'N'], ['—', 'N'], ['—', 'N'], ['—', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print('test_sents:', test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['这', '里', '刊', '登', '湖', '南', '读', '者', '周', '云', '武', '的', '来', '稿', '—', '—', '—']\n"
     ]
    }
   ],
   "source": [
    "print(sent2tokens(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ture: N N N N B-LOC I-LOC N N B-PER I-PER I-PER N N N N N N\n",
      "predicted: N N N N B-LOC I-LOC N N B-PER I-PER I-PER N N N N N N\n"
     ]
    }
   ],
   "source": [
    "print('ture:', ' '.join(sent2labels(test_sents)))\n",
    "print('predicted:', ' '.join(tagger.tag(sent2features(test_sents))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [['河','B-LOC'],['南','I-LO'],['人','N'],['在','N'],['天','B-LOC'],['安','I-LOC'],['门','I-LOC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bias', 'word=河', 'word.istitle=False', 'word.isdigit=False', 'label=B-LOC', 'BOS', '+1:word=南', '+1:word.istitle=False', '+1:label=I-LO']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(a)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ture: B-LOC I-LO N N B-LOC I-LOC I-LOC\n",
      "predicted: B-LOC I-LOC N N B-LOC I-LOC I-LOC\n"
     ]
    }
   ],
   "source": [
    "print('ture:', ' '.join(sent2labels(a)))\n",
    "print('predicted:', ' '.join(tagger.tag(sent2features(a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', ' '.join(tagger.tag(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = '湖南读者周云武的来稿'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', ' '.join(tagger.tag(['这', '里', '刊', '登', '湖', '南', '读', '者', '周', '云', '武', '的', '来', '稿', '—', '—', '—']\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
