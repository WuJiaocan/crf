{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crf测试pku中文语料第4版\n",
    "\n",
    "改进：直接将数据格式为[word, label]的语料库拿来训练，特征提取为前后邻一个字，关注前后的序列，而不是别的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随意抽取一个带人名/地名的句子当作测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pycrfsuite\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    train_sents = []\n",
    "    test_sents = []\n",
    "    pairList = []\n",
    "    f = open('./train_utf16.ner', 'r', encoding='utf_16_le')\n",
    "    for line in f :\n",
    "        line = line.encode('utf-8').decode('utf-8-sig').strip()\n",
    "        if line:\n",
    "            l = line.split(' ')\n",
    "            pairList.append([l[0], l[1]])\n",
    "        else:\n",
    "            train_sents.append(pairList)\n",
    "            pairList = []\n",
    "    f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['藏', 'N'], ['书', 'N'], ['本', 'N'], ['来', 'N'], ['就', 'N'], ['是', 'N'], ['所', 'N'], ['有', 'N'], ['传', 'N'], ['统', 'N'], ['收', 'N'], ['藏', 'N'], ['门', 'N'], ['类', 'N'], ['中', 'N'], ['的', 'N'], ['第', 'N'], ['一', 'N'], ['大', 'N'], ['户', 'N'], ['，', 'N'], ['只', 'N'], ['是', 'N'], ['我', 'N'], ['们', 'N'], ['结', 'N'], ['束', 'N'], ['温', 'N'], ['饱', 'N'], ['的', 'N'], ['时', 'N'], ['间', 'N'], ['太', 'N'], ['短', 'N'], ['而', 'N'], ['已', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'word=' + word,\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word=' + word1\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word=' + word1\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word=藏', 'BOS', '+1:word=书']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(train_sents[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word=书', '-1:word=藏', '+1:word=本']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(train_sents[0])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word=。', '-1:word=已', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(train_sents[0])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['一', 'N'], ['周', 'N'], ['来', 'N'], ['，', 'N'], ['河', 'B-LOC'], ['南', 'I-LOC'], ['西', 'B-LOC'], ['峡', 'I-LOC'], ['符', 'B-PER'], ['祖', 'I-PER'], ['国', 'I-PER'], ['、', 'N'], ['江', 'B-LOC'], ['西', 'I-LOC'], ['广', 'B-LOC'], ['昌', 'I-LOC'], ['吴', 'B-PER'], ['小', 'I-PER'], ['毛', 'I-PER'], ['、', 'N'], ['河', 'B-LOC'], ['北', 'I-LOC'], ['石', 'B-LOC'], ['家', 'I-LOC'], ['庄', 'I-LOC'], ['马', 'B-PER'], ['强', 'I-PER'], ['等', 'N'], ['百', 'N'], ['余', 'N'], ['位', 'N'], ['朋', 'N'], ['友', 'N'], ['给', 'N'], ['本', 'N'], ['刊', 'N'], ['来', 'N'], ['信', 'N'], ['来', 'N'], ['稿', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[889])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['一', 'N'], ['周', 'N'], ['来', 'N'], ['，', 'N'], ['河', 'B-LOC'], ['南', 'I-LOC'], ['西', 'B-LOC'], ['峡', 'I-LOC'], ['符', 'B-PER'], ['祖', 'I-PER'], ['国', 'I-PER'], ['、', 'N'], ['江', 'B-LOC'], ['西', 'I-LOC'], ['广', 'B-LOC'], ['昌', 'I-LOC'], ['吴', 'B-PER'], ['小', 'I-PER'], ['毛', 'I-PER'], ['、', 'N'], ['河', 'B-LOC'], ['北', 'I-LOC'], ['石', 'B-LOC'], ['家', 'I-LOC'], ['庄', 'I-LOC'], ['马', 'B-PER'], ['强', 'I-PER'], ['等', 'N'], ['百', 'N'], ['余', 'N'], ['位', 'N'], ['朋', 'N'], ['友', 'N'], ['给', 'N'], ['本', 'N'], ['刊', 'N'], ['来', 'N'], ['信', 'N'], ['来', 'N'], ['稿', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "test_sents = train_sents[889]\n",
    "print(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(test_sents)]\n",
    "y_test = [sent2labels(test_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一', '周', '来', '，', '河', '南', '西', '峡', '符', '祖', '国', '、', '江', '西', '广', '昌', '吴', '小', '毛', '、', '河', '北', '石', '家', '庄', '马', '强', '等', '百', '余', '位', '朋', '友', '给', '本', '刊', '来', '信', '来', '稿', '。']\n"
     ]
    }
   ],
   "source": [
    "print(sent2tokens(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'N', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'I-PER', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'I-PER', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'B-PER', 'I-PER', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "print(sent2labels(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xseq, yseq in zip(X_train, y_train): \n",
    "    trainer.append(xseq, yseq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1':1.0,\n",
    "    'c2':1e-3,\n",
    "    'max_iterations':50,\n",
    "    'feature.possible_transitions':True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('conll2002_4.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f5252d026d8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002_4.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: ['N', 'N', 'N', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'I-PER', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'I-PER', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'B-PER', 'I-PER', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "predicted: ['N', 'N', 'N', 'N', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'B-PER', 'I-PER', 'I-PER', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'I-PER', 'N', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "print('true:', sent2labels(test_sents))\n",
    "print('predicted:', tagger.tag(sent2features(test_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    '''\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    '''\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "    tagset = set(lb.classes_) - {'N'} \n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)} \n",
    "\n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels=[class_indices[cls] for cls in tagset],\n",
    "        target_names=tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       1.00      0.83      0.91         6\n",
      "      I-LOC       0.78      1.00      0.88         7\n",
      "      B-PER       1.00      0.67      0.80         3\n",
      "      I-PER       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.93      0.86      0.88        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "\n",
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7/3划分句子，划分训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pycrfsuite\n",
    "from itertools import chain\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    train_sents = []\n",
    "    test_sents = []\n",
    "    pairList = []\n",
    "    train = open('./train_data', 'r', encoding='utf-8')\n",
    "    test = open('./test_data', 'r', encoding='utf-8')\n",
    "    for line in train :\n",
    "        line = line.encode('utf-8').decode('utf-8-sig').strip()\n",
    "        if line:\n",
    "            l = line.split(' ')\n",
    "            pairList.append([l[0], l[1]])\n",
    "        else:\n",
    "            train_sents.append(pairList)\n",
    "            pairList = []\n",
    "    for line in test :\n",
    "        line = line.encode('utf-8').decode('utf-8-sig').strip()\n",
    "        if line:\n",
    "            l = line.split(' ')\n",
    "            pairList.append([l[0], l[1]])\n",
    "        else:\n",
    "            test_sents.append(pairList)\n",
    "            pairList = []          \n",
    "    train.close()\n",
    "    test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['“', 'N'], ['能', 'N'], ['选', 'N'], ['出', 'N'], ['一', 'N'], ['个', 'N'], ['好', 'N'], ['村', 'N'], ['长', 'N'], ['来', 'N'], ['，', 'N'], ['是', 'N'], ['我', 'N'], ['们', 'N'], ['老', 'N'], ['百', 'N'], ['姓', 'N'], ['的', 'N'], ['福', 'N'], ['分', 'N'], ['！', 'N'], ['”', 'N'], ['记', 'N'], ['票', 'N'], ['板', 'N'], ['上', 'N'], ['出', 'N'], ['现', 'N'], ['了', 'N'], ['左', 'B-PER'], ['金', 'I-PER'], ['文', 'I-PER'], ['的', 'N'], ['名', 'N'], ['字', 'N'], ['，', 'N'], ['而', 'N'], ['且', 'N'], ['票', 'N'], ['数', 'N'], ['扶', 'N'], ['摇', 'N'], ['直', 'N'], ['上', 'N'], ['，', 'N'], ['远', 'N'], ['远', 'N'], ['超', 'N'], ['过', 'N'], ['另', 'N'], ['外', 'N'], ['两', 'N'], ['名', 'N'], ['候', 'N'], ['选', 'N'], ['人', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['以', 'N'], ['家', 'N'], ['乡', 'N'], ['的', 'N'], ['历', 'N'], ['史', 'N'], ['文', 'N'], ['献', 'N'], ['、', 'N'], ['特', 'N'], ['定', 'N'], ['历', 'N'], ['史', 'N'], ['时', 'N'], ['期', 'N'], ['书', 'N'], ['刊', 'N'], ['、', 'N'], ['某', 'N'], ['一', 'N'], ['名', 'N'], ['家', 'N'], ['或', 'N'], ['名', 'N'], ['著', 'N'], ['的', 'N'], ['多', 'N'], ['种', 'N'], ['出', 'N'], ['版', 'N'], ['物', 'N'], ['为', 'N'], ['专', 'N'], ['题', 'N'], ['，', 'N'], ['注', 'N'], ['意', 'N'], ['精', 'N'], ['品', 'N'], ['、', 'N'], ['非', 'N'], ['卖', 'N'], ['品', 'N'], ['、', 'N'], ['纪', 'N'], ['念', 'N'], ['品', 'N'], ['，', 'N'], ['集', 'N'], ['成', 'N'], ['系', 'N'], ['列', 'N'], ['，', 'N'], ['那', 'N'], ['收', 'N'], ['藏', 'N'], ['的', 'N'], ['过', 'N'], ['程', 'N'], ['就', 'N'], ['已', 'N'], ['经', 'N'], ['够', 'N'], ['您', 'N'], ['玩', 'N'], ['味', 'N'], ['无', 'N'], ['穷', 'N'], ['了', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(test_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089050\n"
     ]
    }
   ],
   "source": [
    "print(line_index)    # 1089050个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'word=' + word,\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word=' + word1\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word=' + word1\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xseq, yseq in zip(X_train, y_train): \n",
    "    trainer.append(xseq, yseq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1':1.0,\n",
    "    'c2':1e-3,\n",
    "    'max_iterations':50,\n",
    "    'feature.possible_transitions':True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('conll2002_5.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f525e3fe198>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002_5.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "predicted: ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "print('true:', sent2labels(test_sents[0]))\n",
    "print('predicted:', tagger.tag(sent2features(test_sents[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    '''\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    '''\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "    tagset = set(lb.classes_) - {'N'} \n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)} \n",
    "\n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels=[class_indices[cls] for cls in tagset],\n",
    "        target_names=tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.87      0.78      0.82      5391\n",
      "      I-LOC       0.83      0.78      0.80      7214\n",
      "      B-ORG       0.82      0.64      0.72      3082\n",
      "      I-ORG       0.83      0.72      0.77     12638\n",
      "      B-PER       0.91      0.75      0.82      2760\n",
      "      I-PER       0.89      0.81      0.85      5463\n",
      "\n",
      "avg / total       0.85      0.75      0.80     36548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "\n",
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
