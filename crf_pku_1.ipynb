{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crf测试pku中文语料第1版\n",
    "\n",
    "训练集：train_utf16.ner的随机70%\n",
    "\n",
    "测试集：train_utf16.ner的随机30%\n",
    "\n",
    "提取特征：word,label,istitle(),isdigit()\n",
    "\n",
    "结果：precision/recall全是1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    train_sents = []\n",
    "    test_sents = []\n",
    "    f = open('./train_utf16.ner', 'r', encoding='utf_16_le')\n",
    "    pairList = []\n",
    "    for line in f:\n",
    "        line = line.encode('utf-8').decode('utf-8-sig').strip()  # 去掉首字前的\\ufeff\n",
    "        if line:\n",
    "            l = line.split(' ')\n",
    "            pairList.append([l[0], l[1]])\n",
    "        else:\n",
    "            r = random.random()\n",
    "            if r < 0.7:\n",
    "                train_sents.append(pairList)\n",
    "            else:\n",
    "                test_sents.append(pairList)\n",
    "            pairList = []\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['精', 'N'], ['品', 'N'], ['、', 'N'], ['专', 'N'], ['题', 'N'], ['、', 'N'], ['系', 'N'], ['列', 'N'], ['、', 'N'], ['稀', 'N'], ['见', 'N'], ['程', 'N'], ['度', 'N'], ['才', 'N'], ['是', 'N'], ['质', 'N'], ['量', 'N'], ['的', 'N'], ['核', 'N'], ['心', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):  # for i in range(len(sent))\n",
    "    word = sent[i][0]\n",
    "    label = sent[i][1]\n",
    "    features = [  # 每个当前字的features\n",
    "        'bias',\n",
    "        'word=' + word,\n",
    "#         'word[-3:]=' + word[-3:],\n",
    "#         'word[-2:]=' + word[-2:],\n",
    "#         'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'label=' + label,\n",
    "#         'label[:2]=' + label[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        label1 = sent[i - 1][1]\n",
    "        features.extend([  # 前一个单词的features\n",
    "            '-1:word=' + word1,\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "#             '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + label1,\n",
    "#             '-1:label[:2]=' + label1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i + 1][0]\n",
    "        label1 = sent[i + 1][1]\n",
    "        features.extend([  # 后一个单词的features\n",
    "            '+1:word=' + word1,\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "#             '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:label=' + label1,\n",
    "#             '+1:label[:2]=' + label1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bias', 'word=精', 'word.istitle=False', 'word.isdigit=False', 'label=N', 'BOS', '+1:word=品', '+1:word.istitle=False', '+1:label=N']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(train_sents[0])[0])  # 第一个list的第一个位置上的word,按照自己定义的特征提取出一些信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "print(sent2labels(train_sents[0])[0])  # 第一个list的第一个位置上的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bias', 'word=。', 'word.istitle=False', 'word.isdigit=False', 'label=N', '-1:word=心', '-1:word.istitle=False', '-1:postag=N', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(train_sents[0])[-1])  # 第一个list的第一个位置上的word,按照自己定义的特征提取出一些信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]  # 不加[]是generator类型，不会输出。加了[]，可直接输出加了[]之后的结果。\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]  # 格式 [[[每个word的特征],[每个word的特征]],（到此处是一个s）,[(每个word的特征)],...]，\n",
    "y_test = [sent2labels(s) for s in test_sents] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xseq, yseq in zip(X_train, y_train):  # zip,打包为元组的列表\n",
    "    trainer.append(xseq, yseq)  # 要train的data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,\n",
    "    'c2': 1e-3,\n",
    "    'max_iterations': 50,\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer.params(): ['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']\n"
     ]
    }
   ],
   "source": [
    "print('trainer.params():', trainer.params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('conll2002_1.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer.logparser.last_iteration: {'num': 50, 'scores': {}, 'loss': 89.900078, 'feature_norm': 29.618714, 'error_norm': 0.053167, 'active_features': 13, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.33}\n"
     ]
    }
   ],
   "source": [
    "print('trainer.logparser.last_iteration:', trainer.logparser.last_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {'num': 50, 'scores': {}, 'loss': 89.900078, 'feature_norm': 29.618714, 'error_norm': 0.053167, 'active_features': 13, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.33}\n"
     ]
    }
   ],
   "source": [
    "print(len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f1ebd232cf8>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002_1.crfsuite')  # 使用训练后的模型，创建用于测试的标注器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_sent: [['以', 'N'], ['家', 'N'], ['乡', 'N'], ['的', 'N'], ['历', 'N'], ['史', 'N'], ['文', 'N'], ['献', 'N'], ['、', 'N'], ['特', 'N'], ['定', 'N'], ['历', 'N'], ['史', 'N'], ['时', 'N'], ['期', 'N'], ['书', 'N'], ['刊', 'N'], ['、', 'N'], ['某', 'N'], ['一', 'N'], ['名', 'N'], ['家', 'N'], ['或', 'N'], ['名', 'N'], ['著', 'N'], ['的', 'N'], ['多', 'N'], ['种', 'N'], ['出', 'N'], ['版', 'N'], ['物', 'N'], ['为', 'N'], ['专', 'N'], ['题', 'N'], ['，', 'N'], ['注', 'N'], ['意', 'N'], ['精', 'N'], ['品', 'N'], ['、', 'N'], ['非', 'N'], ['卖', 'N'], ['品', 'N'], ['、', 'N'], ['纪', 'N'], ['念', 'N'], ['品', 'N'], ['，', 'N'], ['集', 'N'], ['成', 'N'], ['系', 'N'], ['列', 'N'], ['，', 'N'], ['那', 'N'], ['收', 'N'], ['藏', 'N'], ['的', 'N'], ['过', 'N'], ['程', 'N'], ['就', 'N'], ['已', 'N'], ['经', 'N'], ['够', 'N'], ['您', 'N'], ['玩', 'N'], ['味', 'N'], ['无', 'N'], ['穷', 'N'], ['了', 'N'], ['。', 'N']]\n",
      "token of example_sent: 以 家 乡 的 历 史 文 献 、 特 定 历 史 时 期 书 刊 、 某 一 名 家 或 名 著 的 多 种 出 版 物 为 专 题 ， 注 意 精 品 、 非 卖 品 、 纪 念 品 ， 集 成 系 列 ， 那 收 藏 的 过 程 就 已 经 够 您 玩 味 无 穷 了 。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[1]\n",
    "print('example_sent:', example_sent)\n",
    "print(\"token of example_sent:\", ' '.join(sent2tokens(example_sent)), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N\n",
      "Correct:   N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    '''\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    '''\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "    tagset = set(lb.classes_) - {'N'}  # 从9个labels中去除大写字母N\n",
    "    print(tagset)  # {'I-LOC', 'B-MISC', 'B-ORG', 'I-ORG', 'B-LOC', 'I-MISC', 'I-PER', 'B-PER'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    print(tagset)  # ['B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER']\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}  # idx:0,1,2,3,4,5,6,7; cls:8个labels;\n",
    "\n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels=[class_indices[cls] for cls in tagset],\n",
    "        target_names=tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-PER', 'I-LOC', 'B-ORG', 'I-ORG', 'I-PER', 'B-LOC'}\n",
      "['B-LOC', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       1.00      1.00      1.00      5374\n",
      "      I-LOC       1.00      1.00      1.00      7107\n",
      "      B-ORG       1.00      1.00      1.00      3085\n",
      "      I-ORG       1.00      1.00      1.00     12315\n",
      "      B-PER       1.00      1.00      1.00      2707\n",
      "      I-PER       1.00      1.00      1.00      5235\n",
      "\n",
      "avg / total       1.00      1.00      1.00     35823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "\n",
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['藏', 'N'], ['书', 'N'], ['本', 'N'], ['来', 'N'], ['就', 'N'], ['是', 'N'], ['所', 'N'], ['有', 'N'], ['传', 'N'], ['统', 'N'], ['收', 'N'], ['藏', 'N'], ['门', 'N'], ['类', 'N'], ['中', 'N'], ['的', 'N'], ['第', 'N'], ['一', 'N'], ['大', 'N'], ['户', 'N'], ['，', 'N'], ['只', 'N'], ['是', 'N'], ['我', 'N'], ['们', 'N'], ['结', 'N'], ['束', 'N'], ['温', 'N'], ['饱', 'N'], ['的', 'N'], ['时', 'N'], ['间', 'N'], ['太', 'N'], ['短', 'N'], ['而', 'N'], ['已', 'N'], ['。', 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(test_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label是B_LOC的单词共: 5374\n",
      "label是I_LOC的单词共: 7107\n",
      "label是B_ORG的单词共: 3085\n",
      "label是I_ORG的单词共: 12315\n",
      "label是B_PER的单词共: 2707\n",
      "label是I_PER的单词共: 5235\n",
      "除去标签是N的单词共: 35823\n",
      "label是N的单词共: 288971\n",
      "单词总共: 324794\n",
      "324794\n"
     ]
    }
   ],
   "source": [
    "label_B_LOC = 0\n",
    "label_I_LOC = 0\n",
    "label_B_ORG = 0\n",
    "label_I_ORG = 0\n",
    "label_B_PER = 0\n",
    "label_I_PER = 0\n",
    "label_N = 0        \n",
    "index = 0\n",
    "\n",
    "for sent in y_pred:\n",
    "    if sent:\n",
    "        for label in sent:\n",
    "            index += 1\n",
    "            if label == 'B-LOC':\n",
    "                label_B_LOC += 1\n",
    "            if label == 'I-LOC':\n",
    "                label_I_LOC += 1\n",
    "            if label == 'B-ORG':\n",
    "                label_B_ORG += 1\n",
    "            if label == 'I-ORG':\n",
    "                label_I_ORG += 1\n",
    "            if label == 'B-PER':\n",
    "                label_B_PER += 1\n",
    "            if label == 'I-PER':\n",
    "                label_I_PER += 1\n",
    "            if label == 'N':\n",
    "                label_N += 1\n",
    "\n",
    "print('label是B_LOC的单词共:', label_B_LOC)\n",
    "print('label是I_LOC的单词共:', label_I_LOC)\n",
    "print('label是B_ORG的单词共:', label_B_ORG)\n",
    "print('label是I_ORG的单词共:', label_I_ORG)\n",
    "print('label是B_PER的单词共:', label_B_PER)\n",
    "print('label是I_PER的单词共:', label_I_PER)\n",
    "print('除去标签是N的单词共:', label_B_LOC+label_B_ORG+label_B_PER+label_I_LOC+label_I_ORG+label_I_PER)\n",
    "print('label是N的单词共:', label_N)\n",
    "print('单词总共:',label_B_LOC+label_B_ORG+label_B_PER+label_I_LOC+label_I_ORG+label_I_PER+label_N)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
