{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.conll2002.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[('Melbourne', 'NP', 'B-LOC'), ('(', 'Fpa', 'O'), ('Australia', 'NP', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('25', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFE', 'NC', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
    "\n",
    "print(1)\n",
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bias', 'word.lower=melbourne', 'word[-3:]=rne', 'word[-2:]=ne', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=NP', 'postag[:2]=NP', 'BOS', '+1:word.lower=(', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fpa', '+1:postag[:2]=Fp']\n",
      "B-LOC\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Features\n",
    "'''\n",
    "\n",
    "\n",
    "# define some features. In this example we use word identity(BOS), word suffix(单词后缀), word shape and word POS tag(NP);\n",
    "# also, some information from nearby words is used.\n",
    "# This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results\n",
    "\n",
    "def word2features(sent, i):  # for i in range(len(sent))\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [  # 每个当前的单词的features\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        postag1 = sent[i - 1][1]\n",
    "        features.extend([  # 前一个单词的features\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i + 1][0]\n",
    "        postag1 = sent[i + 1][1]\n",
    "        features.extend([  # 后一个单词的features\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "\n",
    "print(sent2features(train_sents[0])[0])  # 第一个list的第一个位置上的word,按照自己定义的特征提取出一些信息\n",
    "print(sent2labels(train_sents[0])[0])  # 第一个list的第一个位置上的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]  # 不加[]是generator类型，不会输出。加了[]，可直接输出加了[]之后的结果。\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]  # 格式 [[[每个word的特征],[每个word的特征]],（到此处是一个s）,[(每个word的特征)],...]，\n",
    "y_test = [sent2labels(s) for s in test_sents]  # 最外面的一层[]是加上去的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer.params(): ['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train the model\n",
    "'''\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):  # zip,打包为元组的列表\n",
    "    trainer.append(xseq, yseq)  # 要train的data\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,\n",
    "    'c2': 1e-3,\n",
    "    'max_iterations': 50,\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "print('trainer.params():', trainer.params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer.logparser.last_iteration: {'num': 50, 'scores': {}, 'loss': 14807.577946, 'feature_norm': 79.110017, 'error_norm': 1262.912078, 'active_features': 11346, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.25}\n",
      "50 {'num': 50, 'scores': {}, 'loss': 14807.577946, 'feature_norm': 79.110017, 'error_norm': 1262.912078, 'active_features': 11346, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.25}\n"
     ]
    }
   ],
   "source": [
    "trainer.train('conll2002_NER-esp.crfsuite')  # #含义是训练出的模型名为：conll2002_NER-esp.crfsuite。\n",
    "\n",
    "print('trainer.logparser.last_iteration:', trainer.logparser.last_iteration)\n",
    "print(len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_sent: [('La', 'DA', 'B-LOC'), ('Coruña', 'NC', 'I-LOC'), (',', 'Fc', 'O'), ('23', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFECOM', 'NP', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n",
      "token of example_sent: La Coruña , 23 may ( EFECOM ) .\n",
      "\n",
      "Predicted: B-LOC I-LOC O O O O B-ORG O O\n",
      "Correct:   B-LOC I-LOC O O O O B-ORG O O\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Make predictions\n",
    "'''\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002_NER-esp.crfsuite')  # 使用训练后的模型，创建用于测试的标注器。\n",
    "\n",
    "example_sent = test_sents[0]\n",
    "print('example_sent:', example_sent)\n",
    "print(\"token of example_sent:\", ' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bias', 'word.lower=coruña', 'word[-3:]=uña', 'word[-2:]=ña', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=NC', 'postag[:2]=NC', '-1:word.lower=la', '-1:word.istitle=True', '-1:word.isupper=False', '-1:postag=DA', '-1:postag[:2]=DA', '+1:word.lower=,', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fc', '+1:postag[:2]=Fc']\n"
     ]
    }
   ],
   "source": [
    "print(sent2features(example_sent)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-LOC', 'B-ORG', 'B-PER', 'I-ORG', 'I-LOC', 'I-PER', 'B-MISC', 'I-MISC'}\n",
      "['B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.78      0.75      0.76      1084\n",
      "      I-LOC       0.66      0.60      0.63       325\n",
      "     B-MISC       0.69      0.47      0.56       339\n",
      "     I-MISC       0.61      0.49      0.54       557\n",
      "      B-ORG       0.79      0.81      0.80      1400\n",
      "      I-ORG       0.80      0.79      0.80      1104\n",
      "      B-PER       0.82      0.87      0.84       735\n",
      "      I-PER       0.87      0.93      0.90       634\n",
      "\n",
      "avg / total       0.77      0.76      0.76      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Evalute the model\n",
    "'''\n",
    "\n",
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    '''\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    '''\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "\n",
    "\n",
    "    tagset = set(lb.classes_) - {'O'}  # 从9个labels中去除大写字母O\n",
    "    print(tagset)  # {'I-LOC', 'B-MISC', 'B-ORG', 'I-ORG', 'B-LOC', 'I-MISC', 'I-PER', 'B-PER'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    print(tagset)  # ['B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER']\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}  # idx:0,1,2,3,4,5,6,7; cls:8个labels;\n",
    "\n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels=[class_indices[cls] for cls in tagset],\n",
    "        target_names=tagset,\n",
    "    )\n",
    "\n",
    "\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "\n",
    "\n",
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of y_pred: 1517\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print('len of y_pred:', len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果中label是B_LOC的单词共: 1044\n"
     ]
    }
   ],
   "source": [
    "label_B_LOC = 0\n",
    "\n",
    "for sent in y_pred:\n",
    "    for label in sent:\n",
    "        if label == 'B-LOC':\n",
    "            label_B_LOC += 1\n",
    "print('预测结果中label是B_LOC的单词共:', label_B_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集中label是B_LOC的单词共: 1084\n"
     ]
    }
   ],
   "source": [
    "label_B_LOC1 = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    for pair in sent:\n",
    "        if pair[2] == 'B-LOC':\n",
    "            label_B_LOC1 += 1\n",
    "print('测试集中label是B_LOC的单词共:', label_B_LOC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted:\", ' '.join(tagger.tag(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
